{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bbb8ca14-ef56-4452-97a6-95247be66427",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cdsw/.local/lib/python3.9/site-packages/datasets/table.py:1421: FutureWarning: promote has been superseded by mode='default'.\n",
      "  table = cls._concat_blocks(blocks, axis=0)\n"
     ]
    }
   ],
   "source": [
    "base_model = 't5-small'\n",
    "from transformers import AutoTokenizer, T5ForConditionalGeneration\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model)\n",
    "model = T5ForConditionalGeneration.from_pretrained(base_model)\n",
    "\n",
    "#CKPT = 'facebook/bart-large'\n",
    "#from transformers import AutoTokenizer, BartTokenizer, BartModel, BartForConditionalGeneration\n",
    "#tokenizer = AutoTokenizer.from_pretrained('facebook/bart-large')\n",
    "#model = BartForConditionalGeneration.from_pretrained('facebook/bart-large')\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "train_data = load_dataset('wikisql', split=\"train[:100%]+validation[:100%]\")\n",
    "#train_data = load_dataset('wikisql', split=\"train+validation\")\n",
    "test_data = load_dataset('wikisql', split='test')\n",
    "\n",
    "def format_dataset(example):\n",
    " return {'input': 'translate to SQL: ' + example['question'], 'target': example['sql']['human_readable']}\n",
    "\n",
    "train_data = train_data.map(format_dataset, remove_columns=train_data.column_names)\n",
    "test_data = test_data.map(format_dataset, remove_columns=test_data.column_names)\n",
    "\n",
    "import shutil\n",
    "\n",
    "def remove_dir(dir_path):\n",
    "    try:\n",
    "        shutil.rmtree(dir_path)\n",
    "        print(f\"Folder '{dir_path}' has been deleted.\")\n",
    "    except Exception as e:\n",
    "        # Ignore errors, you can print a message if needed\n",
    "        print(f\"Folder '{dir_path}' has been deleted.\")\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53249be2-35a6-4c42-90f5-6e164cbb2dd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0 Memory Used: 230.8145 MB\n",
      "\n",
      "Parameters:\n",
      "Total parameters: 60.5066 M\n",
      "\n",
      "Data types:\n",
      "torch.float32, 60.5066 M, 100.00 %\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def print_param_precision(model):\n",
    "  dtypes = {}\n",
    "  for _, p in model.named_parameters():\n",
    "      dtype = p.dtype\n",
    "      if dtype not in dtypes:\n",
    "          dtypes[dtype] = 0\n",
    "      dtypes[dtype] += p.numel()\n",
    "  total = 0\n",
    "  for k, v in dtypes.items():\n",
    "      total += v\n",
    "  for k, v in dtypes.items():\n",
    "      print(f\"{k}, {v / 10**6:.4f} M, {v / total*100:.2f} %\")\n",
    "\n",
    "def print_parameters(model):\n",
    "  # Count the total parameters\n",
    "  total_params = sum(p.numel() for p in model.parameters())\n",
    "  print(f\"Total parameters: {total_params/10**6:.4f} M\")\n",
    "\n",
    "device_map = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"{device_map} Memory Used: {model.get_memory_footprint() / 1024**2:.4f} MB\")\n",
    "print(\"\\nParameters:\")\n",
    "print_parameters(model)\n",
    "print(\"\\nData types:\")\n",
    "print_param_precision(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c9631a1-5416-4c82-91c8-ebc2f3ded8f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input', 'target'],\n",
       "    num_rows: 64776\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20095e22-344f-478f-8620-b5e81c8f14d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "736dd8fa119f4061b4dc0cf4e1089f0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Mean: 19.8508, %-Input > 256:0.0,  %-Input > 128:0.0, %-Input > 64:0.0002 Output Mean:20.0403, %-Output > 256:0.0, %-Output > 128:0.0002, %-Output > 64:0.0005\n"
     ]
    }
   ],
   "source": [
    "# map article and summary len to dict as well as if sample is longer than 512 tokens\n",
    "def map_to_length(x):\n",
    "  x[\"input_len\"] = len(tokenizer(x[\"input\"]).input_ids)\n",
    "  x[\"input_longer_256\"] = int(x[\"input_len\"] > 256)\n",
    "  x[\"input_longer_128\"] = int(x[\"input_len\"] > 128)\n",
    "  x[\"input_longer_64\"] = int(x[\"input_len\"] > 64)\n",
    "  x[\"out_len\"] = len(tokenizer(x[\"target\"]).input_ids)\n",
    "  x[\"out_longer_256\"] = int(x[\"out_len\"] > 256)\n",
    "  x[\"out_longer_128\"] = int(x[\"out_len\"] > 128)\n",
    "  x[\"out_longer_64\"] = int(x[\"out_len\"] > 64)\n",
    "  return x\n",
    "\n",
    "sample_size = 10000\n",
    "data_stats = train_data.select(range(sample_size)).map(map_to_length, num_proc=4)\n",
    "\n",
    "def compute_and_print_stats(x):\n",
    "  if len(x[\"input_len\"]) == sample_size:\n",
    "    print(\n",
    "        \"Input Mean: {}, %-Input > 256:{},  %-Input > 128:{}, %-Input > 64:{} Output Mean:{}, %-Output > 256:{}, %-Output > 128:{}, %-Output > 64:{}\".format(\n",
    "            sum(x[\"input_len\"]) / sample_size,\n",
    "            sum(x[\"input_longer_256\"]) / sample_size,\n",
    "            sum(x[\"input_longer_128\"]) / sample_size,\n",
    "            sum(x[\"input_longer_64\"]) / sample_size,   \n",
    "            sum(x[\"out_len\"]) / sample_size,\n",
    "            sum(x[\"out_longer_256\"]) / sample_size,\n",
    "            sum(x[\"out_longer_128\"]) / sample_size,\n",
    "            sum(x[\"out_longer_64\"]) / sample_size,\n",
    "        )\n",
    "    )\n",
    "\n",
    "output = data_stats.map(\n",
    "  compute_and_print_stats, \n",
    "  batched=True,\n",
    "  batch_size=-1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d2fcd398-7655-4d4e-9bc0-d9386ba3e7f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize the examples\n",
    "def convert_to_features(example_batch):\n",
    "    input_encodings = tokenizer.batch_encode_plus(example_batch['input'], truncation = True, padding=\"max_length\", max_length=128)\n",
    "    target_encodings = tokenizer.batch_encode_plus(example_batch['target'], truncation = True, padding=\"max_length\", max_length=128)\n",
    "   \n",
    "    encodings = {\n",
    "        'input_ids': input_encodings['input_ids'],\n",
    "        'labels': target_encodings['input_ids']\n",
    "    }\n",
    "\n",
    "    return encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "712cc95b-8780-4db3-b2a5-d3d009395b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.map(convert_to_features, batched=True, remove_columns=train_data.column_names)\n",
    "test_data = test_data.map(convert_to_features, batched=True, remove_columns=test_data.column_names)\n",
    "\n",
    "#columns = ['input_ids', 'attention_mask', 'labels', 'decoder_attention_mask']\n",
    "columns = ['input_ids', 'labels']\n",
    "\n",
    "train_data.set_format(type='torch', columns=columns)\n",
    "test_data.set_format(type='torch', columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "73057e5d-97ff-457f-89ba-ada4b55036c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Seq2SeqTrainer, Seq2SeqTrainingArguments, TrainerCallback     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f16d80f-6f81-4392-b22d-c4dbe0fe8172",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder 'trainoutput-wikisql' has been deleted.\n"
     ]
    }
   ],
   "source": [
    "training_output = \"trainoutput-wikisql\"\n",
    "remove_dir(training_output) \n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=training_output,\n",
    "    per_device_train_batch_size=16,\n",
    "    num_train_epochs=5,\n",
    "    per_device_eval_batch_size=16,\n",
    "    predict_with_generate=True,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    do_train=True,\n",
    "    #do_eval=True,\n",
    "    logging_steps=500,\n",
    "    save_strategy=\"epoch\",\n",
    "    report_to=\"tensorboard\", #bypass MLflow\n",
    "    overwrite_output_dir=True\n",
    "    #fp16=True, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b17dc232-75da-4ef5-8745-e6719af0ee89",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5900/3190919124.py:2: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate\n",
      "  rouge = load_metric(\"rouge\")\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_metric\n",
    "rouge = load_metric(\"rouge\")\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels_ids = pred.label_ids\n",
    "    pred_ids = pred.predictions\n",
    "\n",
    "    # all unnecessary tokens are removed\n",
    "    pred_str = tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n",
    "    labels_ids[labels_ids == -100] = tokenizer.pad_token_id\n",
    "    label_str = tokenizer.batch_decode(labels_ids, skip_special_tokens=True)\n",
    "\n",
    "    rouge_output = rouge.compute(predictions=pred_str, references=label_str, rouge_types=[\"rouge2\"])[\"rouge2\"].mid\n",
    "\n",
    "    return {\n",
    "        \"rouge2_precision\": round(rouge_output.precision, 4),\n",
    "        \"rouge2_recall\": round(rouge_output.recall, 4),\n",
    "        \"rouge2_fmeasure\": round(rouge_output.fmeasure, 4),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0ea4730e-7937-48f4-8309-786ee54a42f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    }
   ],
   "source": [
    "# instantiate trainer\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    compute_metrics=compute_metrics,\n",
    "    train_dataset=train_data,\n",
    "    eval_dataset=test_data,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5ab7cb-2c44-4531-b54b-b018cfa517f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5dac4e6f-6f7a-4925-9fc4-6c6f7f951459",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='20245' max='20245' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [20245/20245 48:51, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rouge2 Precision</th>\n",
       "      <th>Rouge2 Recall</th>\n",
       "      <th>Rouge2 Fmeasure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.099700</td>\n",
       "      <td>0.080498</td>\n",
       "      <td>0.405900</td>\n",
       "      <td>0.332400</td>\n",
       "      <td>0.358500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.083400</td>\n",
       "      <td>0.070028</td>\n",
       "      <td>0.561300</td>\n",
       "      <td>0.475700</td>\n",
       "      <td>0.506800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.076000</td>\n",
       "      <td>0.065481</td>\n",
       "      <td>0.634700</td>\n",
       "      <td>0.549100</td>\n",
       "      <td>0.580600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.074200</td>\n",
       "      <td>0.063457</td>\n",
       "      <td>0.621200</td>\n",
       "      <td>0.537300</td>\n",
       "      <td>0.568200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.070100</td>\n",
       "      <td>0.062872</td>\n",
       "      <td>0.678300</td>\n",
       "      <td>0.595100</td>\n",
       "      <td>0.626000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W kineto_shim.cpp:372] Profiler is not initialized: skipping step() invocation\n",
      "[W kineto_shim.cpp:372] Profiler is not initialized: skipping step() invocation\n",
      "[W kineto_shim.cpp:372] Profiler is not initialized: skipping step() invocation\n",
      "STAGE:2023-11-29 09:45:06 5900:5900 ActivityProfilerController.cpp:312] Completed Stage: Warm Up\n",
      "STAGE:2023-11-29 09:45:06 5900:5900 ActivityProfilerController.cpp:318] Completed Stage: Collection\n",
      "STAGE:2023-11-29 09:45:06 5900:5900 ActivityProfilerController.cpp:322] Completed Stage: Post Processing\n",
      "STAGE:2023-11-29 09:45:10 5900:5900 ActivityProfilerController.cpp:312] Completed Stage: Warm Up\n",
      "STAGE:2023-11-29 09:45:11 5900:5900 ActivityProfilerController.cpp:318] Completed Stage: Collection\n",
      "STAGE:2023-11-29 09:45:11 5900:5900 ActivityProfilerController.cpp:322] Completed Stage: Post Processing\n",
      "/home/cdsw/.local/lib/python3.9/site-packages/transformers/generation/utils.py:1273: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "/home/cdsw/.local/lib/python3.9/site-packages/transformers/generation/utils.py:1273: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "/home/cdsw/.local/lib/python3.9/site-packages/transformers/generation/utils.py:1273: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "/home/cdsw/.local/lib/python3.9/site-packages/transformers/generation/utils.py:1273: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "/home/cdsw/.local/lib/python3.9/site-packages/transformers/generation/utils.py:1273: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch.profiler\n",
    "\n",
    "class ProfCallback(TrainerCallback):\n",
    "    def __init__(self, prof):\n",
    "        self.prof = prof\n",
    "\n",
    "    def on_step_end(self, args, state, control, **kwargs):\n",
    "        self.prof.step()\n",
    "        \n",
    "with torch.profiler.profile(activities=[torch.profiler.ProfilerActivity.CPU,\n",
    "                                        torch.profiler.ProfilerActivity.CUDA], \n",
    "                            schedule=torch.profiler.schedule(skip_first=3, wait=1, warmup=1, active=2, repeat=2),\n",
    "                            on_trace_ready=torch.profiler.tensorboard_trace_handler(training_output),\n",
    "                            profile_memory=True,\n",
    "                            with_stack=True,\n",
    "                            record_shapes=True) as prof:\n",
    "    trainer.add_callback(ProfCallback(prof=prof))\n",
    "    trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d8aca6e0-787e-47b7-9024-632bebeaa1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "885eb1a5-400e-4a9a-8a08-9af85cf793b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('trainoutput-wikisql/tokenizer_config.json',\n",
       " 'trainoutput-wikisql/special_tokens_map.json',\n",
       " 'trainoutput-wikisql/spiece.model',\n",
       " 'trainoutput-wikisql/added_tokens.json',\n",
       " 'trainoutput-wikisql/tokenizer.json')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.save_pretrained(training_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c6449cf4-8f65-4718-92c1-c07ea424ae31",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.create_model_card()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e223398e-68ff-4c55-a731-5fc6d28b272c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clear kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "397c397b-602f-4fe9-9a80-be035b17a9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_model = \"trainoutput-wikisql\"\n",
    "#ft_model = 't5-base'\n",
    "base_model = 't5-small'\n",
    "from transformers import AutoTokenizer, T5ForConditionalGeneration\n",
    "tokenizer = AutoTokenizer.from_pretrained(ft_model)\n",
    "model = T5ForConditionalGeneration.from_pretrained(ft_model)\n",
    "from datasets import load_dataset\n",
    "\n",
    "test_data = load_dataset('wikisql', split='test')\n",
    "\n",
    "def translate_to_sql(text):\n",
    "    inputs = tokenizer(text, padding='longest', max_length=128, return_tensors='pt')\n",
    "    input_ids = inputs.input_ids\n",
    "    attention_mask = inputs.attention_mask\n",
    "    #output = model.generate(input_ids, attention_mask=attention_mask, max_length=64)\n",
    "    output = model.generate(input_ids, max_length=128)\n",
    "    \n",
    "    return tokenizer.decode(output[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fa330f81-aa6c-41ad-af79-c34f07b2ba60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "translate to SQL: Who was the winning driver when the grand Prix was at Belgian Grand Prix?\n",
      "Predict. :SELECT Winning driver FROM table WHERE Grand Prix = Belgian Grand Prix\n",
      "Expected: SELECT Winning Driver FROM table WHERE Grand Prix = Belgian Grand Prix\n",
      "=================================\n",
      "\n",
      "translate to SQL: Which races did Paul Greifzu win?\n",
      "Predict. :SELECT Races FROM table WHERE Winner = Paul Greifzu\n",
      "Expected: SELECT Race Name FROM table WHERE Winning driver = Paul Greifzu\n",
      "=================================\n",
      "\n",
      "translate to SQL: What is the % of total capacity when the generators is 4048?\n",
      "Predict. :SELECT % of total capacity FROM table WHERE generators = 4048\n",
      "Expected: SELECT % of total Capacity FROM table WHERE Number of Generators = 4048\n",
      "=================================\n",
      "\n",
      "translate to SQL: What is the acronym for the school whose website is ul.edu.lb\n",
      "Predict. :SELECT Acronyme FROM table WHERE Website = ul.edu.lb\n",
      "Expected: SELECT Acronym FROM table WHERE Website = ul.edu.lb\n",
      "=================================\n",
      "\n",
      "translate to SQL: What is the population in the city of Pomorskie?\n",
      "Predict. :SELECT COUNT Population in Pomorskie\n",
      "Expected: SELECT Population in 1000 (1931) FROM table WHERE Voivodeship Separate city = pomorskie\n",
      "=================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'SELECT COUNT Model FROM table WHERE BERT architecture = HuggingFace Hub'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(200,300,20):\n",
    "  print('translate to SQL: ' + test_data[i]['question'])\n",
    "  print('Predict. :' + translate_to_sql('translate to SQL: ' + test_data[i]['question']))\n",
    "  print('Expected: ' + test_data[i]['sql']['human_readable'])\n",
    "  print('=================================\\n')\n",
    "    \n",
    "\n",
    "text = \"translate to SQL: How many model with BERT architecture are in the HuggingFace Hub?\"\n",
    "#text = \"translate to SQL: The stenhousemuir team had how many highest attendances?\"\n",
    "translate_to_sql(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c521fe2-1b72-43b3-8be3-db74c6e90c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "!deepspeed --hostfile {myhostfile} \\\n",
    "--launcher pdsh \\\n",
    "--num_gpus {worker_gpu} --num_nodes {NUM_WORKERS} \\\n",
    "--master_addr {MASTER_IP} \\\n",
    "--ssh_port {sshd_port} {train_script} \\\n",
    "--model_id google/flan-t5-large \\\n",
    "--dataset_path data \\\n",
    "--epochs 3 \\\n",
    "--per_device_train_batch_size 1 \\\n",
    "--per_device_eval_batch_size 8 \\\n",
    "--generation_max_length 129 \\\n",
    "--lr 1e-4 \\\n",
    "--deepspeed {deepspeed_cfg}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55398d5a-eba4-4860-accb-3421e1790a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!deepspeed --hostfile {myhostfile} \\\n",
    "--launcher pdsh \\\n",
    "--num_gpus {worker_gpu} --num_nodes {NUM_WORKERS} \\\n",
    "--master_addr {MASTER_IP} \\\n",
    "--ssh_port {sshd_port} {train_script} \\\n",
    "--deepspeed --deepspeed_config {deepspeed_cfg}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "854e16a8-afd6-4a90-b324-f89293a6d4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_dir(dir_path):\n",
    "    try:\n",
    "        shutil.rmtree(dir_path)\n",
    "        print(f\"Folder '{dir_path}' has been deleted.\")\n",
    "    except Exception as e:\n",
    "        # Ignore errors, you can print a message if needed\n",
    "        print(f\"Folder '{dir_path}' has been deleted.\")\n",
    "        \n",
    "base_model = \"bloom-1b1\"\n",
    "base_model_name = \"bloom-1b1\"\n",
    "merged_model = \"merged_bloom-1b1\"\n",
    "training_output = \"training_bloom-1b1\"\n",
    "remove_dir(training_output) \n",
    "remove_dir(merged_model)\n",
    "remove_dir(trainlogs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6fa0e9b-ad08-4482-9668-78ff7ad4b057",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_cmd = subprocess.Popen([f'bash -c \"{cml_cmd}\" '], shell=True)\n",
    "main_cmd.communicate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd64ae4b-98f0-4f50-a700-034694913ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please restart the iPython kernel manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec8ff9e-40a6-4aa5-9fe0-4f7e370c2d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!deepspeed --hostfile {myhostfile} \\\n",
    "--launcher pdsh \\\n",
    "--num_gpus {worker_gpu} --num_nodes {NUM_WORKERS} \\\n",
    "--master_addr {MASTER_IP} \\\n",
    "--ssh_port {sshd_port} run_translation.py \\\n",
    "--model_name_or_path t5-large --per_device_train_batch_size 1 \\\n",
    "--deepspeed {deepspeed_cfg} \\\n",
    "--output_dir output_dir --overwrite_output_dir --fp16 \\\n",
    "--do_train --max_train_samples 500 --num_train_epochs 1 \\\n",
    "--dataset_name wmt16 --dataset_config \"ro-en\" \\\n",
    "--source_lang en --target_lang ro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c071a5d-61c1-4dbd-83e2-dab7e846a3f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
