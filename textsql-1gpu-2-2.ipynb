{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb8ca14-ef56-4452-97a6-95247be66427",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "base_model = 't5-large' #770 million\n",
    "#base_model = 't5-base' #220 million\n",
    "#base_model = 't5-small' #60 million\n",
    "dataset = 'wikisql'\n",
    "dataset_path = \"wikisql_tok_dataset\"\n",
    "training_output = \"trainoutput-wikisql\"\n",
    "batch_size = 32\n",
    "eval_size = 32\n",
    "epoch_num = 3\n",
    "\n",
    "from datasets import load_dataset, load_from_disk\n",
    "import shutil\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import evaluate\n",
    "import torch\n",
    "from transformers import (AutoTokenizer,\n",
    "                          GenerationConfig,\n",
    "                          T5ForConditionalGeneration,\n",
    "                          Seq2SeqTrainer, \n",
    "                          Seq2SeqTrainingArguments, \n",
    "                          TrainerCallback,\n",
    "                          EarlyStoppingCallback,\n",
    "                          is_tensorboard_available,\n",
    "                          DataCollatorForSeq2Seq)\n",
    "\n",
    "os.environ['TOKENIZERS_PARALLELISM'] = 'false'\n",
    "\n",
    "model = T5ForConditionalGeneration.from_pretrained(base_model)\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model)\n",
    "\n",
    "gen_cfg = GenerationConfig.from_model_config(model.config)\n",
    "gen_cfg.max_new_tokens = 128\n",
    "gen_cfg.min_length = 1\n",
    "\n",
    "train_data = load_dataset(dataset, split=\"train[:100%]\")\n",
    "eval_data = load_dataset(dataset, split=\"validation[:100%]\")\n",
    "test_data = load_dataset(dataset, split=\"test[:100%]\")\n",
    "\n",
    "def format_dataset(example):\n",
    " return {'input': 'translate to SQL: ' + example['question'], 'target': example['sql']['human_readable']}\n",
    "\n",
    "train_data = train_data.map(format_dataset, remove_columns=train_data.column_names)\n",
    "test_data = test_data.map(format_dataset, remove_columns=test_data.column_names)\n",
    "eval_data = eval_data.map(format_dataset, remove_columns=eval_data.column_names)\n",
    "\n",
    "def remove_dir(dir_path):\n",
    "    try:\n",
    "        shutil.rmtree(dir_path)\n",
    "        print(f\"Folder '{dir_path}' has been deleted.\")\n",
    "    except Exception as e:\n",
    "        # Ignore errors, you can print a message if needed\n",
    "        print(f\"Folder '{dir_path}' has been deleted.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53249be2-35a6-4c42-90f5-6e164cbb2dd7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def print_param_precision(model):\n",
    "  dtypes = {}\n",
    "  for _, p in model.named_parameters():\n",
    "      dtype = p.dtype\n",
    "      if dtype not in dtypes:\n",
    "          dtypes[dtype] = 0\n",
    "      dtypes[dtype] += p.numel()\n",
    "  total = 0\n",
    "  for k, v in dtypes.items():\n",
    "      total += v\n",
    "  for k, v in dtypes.items():\n",
    "      print(f\"{k}, {v / 10**6:.4f} M, {v / total*100:.2f} %\")\n",
    "\n",
    "def print_parameters(model):\n",
    "  # Count the total parameters\n",
    "  total_params = sum(p.numel() for p in model.parameters())\n",
    "  print(f\"Total parameters: {total_params/10**6:.4f} M\")\n",
    "\n",
    "device_map = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"{device_map} Memory Used: {model.get_memory_footprint() / 1024**2:.4f} MB\")\n",
    "print(\"\\nParameters:\")\n",
    "print_parameters(model)\n",
    "print(\"\\nData types:\")\n",
    "print_param_precision(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c9631a1-5416-4c82-91c8-ebc2f3ded8f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20095e22-344f-478f-8620-b5e81c8f14d8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Find the entry with the least number of zero padding\n",
    "tokenizer2 = AutoTokenizer.from_pretrained(base_model)\n",
    "train_data2 = load_dataset(dataset, split=\"train[:100%]\")\n",
    "\n",
    "def format_dataset(example):\n",
    "    return {'input': 'translate to SQL: ' + example['question'], 'target': example['sql']['human_readable']}\n",
    "\n",
    "tokenized_dataset = train_data2.map(format_dataset, remove_columns=train_data2.column_names)\n",
    "tokenized_dataset = tokenizer(tokenized_dataset[\"input\"], padding=True, truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "# Find the entry with the least number of zero padding\n",
    "min_zeros_entry = None\n",
    "min_zeros_count = float('inf')\n",
    "non_zeros_count = None\n",
    "\n",
    "for idx, input_ids in enumerate(tokenized_dataset[\"input_ids\"]):\n",
    "    # Assuming \"input_ids\" is a PyTorch tensor\n",
    "    zeros_count = torch.sum(input_ids == 0).item()  # Counting the number of zeros (padding tokens)\n",
    "    if zeros_count < min_zeros_count:\n",
    "        min_zeros_count = zeros_count\n",
    "        min_zeros_entry = idx\n",
    "        non_zeros_count = len(input_ids) - zeros_count\n",
    "\n",
    "# Print the result\n",
    "print(f\"The entry with the least number of zero padding is at index {min_zeros_entry}\")\n",
    "print(f\"Total non-padded items of the tensor index {min_zeros_entry} is {non_zeros_count}\")\n",
    "print(f\"Length of tensor at index {min_zeros_entry}: {len(input_ids)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2fcd398-7655-4d4e-9bc0-d9386ba3e7f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def convert_to_features(example_batch):\n",
    "    input_encodings = tokenizer.batch_encode_plus(example_batch['input'], truncation = True, padding=\"max_length\", pad_to_max_length=True, max_length=96)\n",
    "    target_encodings = tokenizer.batch_encode_plus(example_batch['target'], truncation = True, padding=\"max_length\", pad_to_max_length=True, max_length=96)\n",
    "   \n",
    "    encodings = {\n",
    "        'input_ids': input_encodings['input_ids'],\n",
    "        'labels': target_encodings['input_ids']\n",
    "    }\n",
    "\n",
    "    return encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712cc95b-8780-4db3-b2a5-d3d009395b29",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "remove_dir(dataset_path)\n",
    "train_data = train_data.map(convert_to_features, batched=True, remove_columns=train_data.column_names)\n",
    "test_data = test_data.map(convert_to_features, batched=True, remove_columns=test_data.column_names)\n",
    "eval_data = eval_data.map(convert_to_features, batched=True, remove_columns=eval_data.column_names)\n",
    "\n",
    "#columns = ['input_ids', 'attention_mask', 'labels', 'decoder_attention_mask']\n",
    "columns = ['input_ids', 'labels']\n",
    "\n",
    "train_data.set_format(type='torch', columns=columns)\n",
    "test_data.set_format(type='torch', columns=columns)\n",
    "eval_data.set_format(type='torch', columns=columns)\n",
    "\n",
    "train_data.save_to_disk(os.path.join(dataset_path,\"train\"))\n",
    "test_data.save_to_disk(os.path.join(dataset_path,\"test\"))\n",
    "eval_data.save_to_disk(os.path.join(dataset_path,\"eval\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee3a0f7-403d-458a-bfc1-3fb31b1bdcaa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "remove_dir(training_output)\n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=training_output, \n",
    "    generation_max_length=128,\n",
    "    generation_num_beams=4,\n",
    "    generation_config=gen_cfg, # applicable for Seq2SeqTrainingArguments\n",
    "    per_device_train_batch_size=batch_size, # Above 64 results in no traininglog and higher loss Seq2SeqTrainingArguments\n",
    "    num_train_epochs=epoch_num, # Below 5 will result in failed inference.\n",
    "    per_device_eval_batch_size=eval_size, #lower due to lower eval_dataset than train_dataset Seq2SeqTrainingArguments\n",
    "    predict_with_generate=True, # False will increase VRAM and potentially OOM # applicable for Seq2SeqTrainingArguments\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    #evaluation_strategy=\"steps\",\n",
    "    load_best_model_at_end=True, \n",
    "    do_train=True,\n",
    "    do_eval=True,\n",
    "    save_strategy=\"epoch\",\n",
    "    overwrite_output_dir=True,\n",
    "    fp16=False, #lower VRAM utilization #False for T5-large https://discuss.huggingface.co/t/t5-variants-return-training-loss-0-and-validation-loss-nan-while-fine-tuning/30839\n",
    "    #bf16=True, #not working for every GPU\n",
    "    report_to=\"tensorboard\", #bypass MLflow\n",
    "    logging_dir=f\"{training_output}/logs\",\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=500,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4aec6ea-386b-424f-954d-d3f7e5ebc9d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datasets import load_metric\n",
    "rouge = load_metric(\"rouge\")\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels_ids = pred.label_ids\n",
    "    pred_ids = pred.predictions\n",
    "\n",
    "    # all unnecessary tokens are removed\n",
    "    pred_str = tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n",
    "    labels_ids[labels_ids == -100] = tokenizer.pad_token_id\n",
    "    label_str = tokenizer.batch_decode(labels_ids, skip_special_tokens=True)\n",
    "\n",
    "    rouge_output = rouge.compute(predictions=pred_str, references=label_str, rouge_types=[\"rouge2\"])[\"rouge2\"].mid\n",
    "\n",
    "    return {\n",
    "        \"rouge2_precision\": round(rouge_output.precision, 4),\n",
    "        \"rouge2_recall\": round(rouge_output.recall, 4),\n",
    "        \"rouge2_fmeasure\": round(rouge_output.fmeasure, 4),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c0da20a-ebde-4844-a480-1907bb896f38",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def custom_rewrite_logs(d, mode):\n",
    "    new_d = {}\n",
    "    eval_prefix = \"eval_\"\n",
    "    eval_prefix_len = len(eval_prefix)\n",
    "    test_prefix = \"test_\"\n",
    "    test_prefix_len = len(test_prefix)\n",
    "    for k, v in d.items():\n",
    "        if mode == 'eval' and k.startswith(eval_prefix):\n",
    "            if k[eval_prefix_len:] == 'loss':\n",
    "                new_d[\"combined/\" + k[eval_prefix_len:]] = v\n",
    "        elif mode == 'test' and k.startswith(test_prefix):\n",
    "            if k[test_prefix_len:] == 'loss':\n",
    "                new_d[\"combined/\" + k[test_prefix_len:]] = v\n",
    "        elif mode == 'train':\n",
    "            if k == 'loss':\n",
    "                new_d[\"combined/\" + k] = v\n",
    "    return new_d\n",
    "\n",
    "\n",
    "class CombinedTensorBoardCallback(TrainerCallback):\n",
    "    \"\"\"\n",
    "    A [`TrainerCallback`] that sends the logs to [TensorBoard](https://www.tensorflow.org/tensorboard).\n",
    "    Args:\n",
    "        tb_writer (`SummaryWriter`, *optional*):\n",
    "            The writer to use. Will instantiate one if not set.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, tb_writers=None):\n",
    "        has_tensorboard = is_tensorboard_available()\n",
    "        if not has_tensorboard:\n",
    "            raise RuntimeError(\n",
    "                \"TensorBoardCallback requires tensorboard to be installed. Either update your PyTorch version or\"\n",
    "                \" install tensorboardX.\"\n",
    "            )\n",
    "        if has_tensorboard:\n",
    "            try:\n",
    "                from torch.utils.tensorboard import SummaryWriter  # noqa: F401\n",
    "\n",
    "                self._SummaryWriter = SummaryWriter\n",
    "            except ImportError:\n",
    "                try:\n",
    "                    from tensorboardX import SummaryWriter\n",
    "\n",
    "                    self._SummaryWriter = SummaryWriter\n",
    "                except ImportError:\n",
    "                    self._SummaryWriter = None\n",
    "        else:\n",
    "            self._SummaryWriter = None\n",
    "        self.tb_writers = tb_writers\n",
    "\n",
    "    def _init_summary_writer(self, args, log_dir=None):\n",
    "        log_dir = log_dir or args.logging_dir\n",
    "        if self._SummaryWriter is not None:\n",
    "            self.tb_writers = dict(train=self._SummaryWriter(log_dir=os.path.join(log_dir, 'train')),\n",
    "                                   eval=self._SummaryWriter(log_dir=os.path.join(log_dir, 'eval')))\n",
    "\n",
    "    def on_train_begin(self, args, state, control, **kwargs):\n",
    "        if not state.is_world_process_zero:\n",
    "            return\n",
    "\n",
    "        log_dir = None\n",
    "\n",
    "        if state.is_hyper_param_search:\n",
    "            trial_name = state.trial_name\n",
    "            if trial_name is not None:\n",
    "                log_dir = os.path.join(args.logging_dir, trial_name)\n",
    "\n",
    "        if self.tb_writers is None:\n",
    "            self._init_summary_writer(args, log_dir)\n",
    "\n",
    "        for k, tbw in self.tb_writers.items():\n",
    "            tbw.add_text(\"args\", args.to_json_string())\n",
    "            if \"model\" in kwargs:\n",
    "                model = kwargs[\"model\"]\n",
    "                if hasattr(model, \"config\") and model.config is not None:\n",
    "                    model_config_json = model.config.to_json_string()\n",
    "                    tbw.add_text(\"model_config\", model_config_json)\n",
    "            # Version of TensorBoard coming from tensorboardX does not have this method.\n",
    "            if hasattr(tbw, \"add_hparams\"):\n",
    "                tbw.add_hparams(args.to_sanitized_dict(), metric_dict={})\n",
    "\n",
    "    def on_log(self, args, state, control, logs=None, **kwargs):\n",
    "        if not state.is_world_process_zero:\n",
    "            return\n",
    "\n",
    "        if self.tb_writers is None:\n",
    "            self._init_summary_writer(args)\n",
    "\n",
    "        for tbk, tbw in self.tb_writers.items():\n",
    "            logs_new = custom_rewrite_logs(logs, mode=tbk)\n",
    "            for k, v in logs_new.items():\n",
    "                if isinstance(v, (int, float)):\n",
    "                    tbw.add_scalar(k, v, state.global_step)\n",
    "                else:\n",
    "                    logger.warning(\n",
    "                        \"Trainer is attempting to log a value of \"\n",
    "                        f'\"{v}\" of type {type(v)} for key \"{k}\" as a scalar. '\n",
    "                        \"This invocation of Tensorboard's writer.add_scalar() \"\n",
    "                        \"is incorrect so we dropped this attribute.\"\n",
    "                    )\n",
    "            tbw.flush()\n",
    "\n",
    "    def on_train_end(self, args, state, control, **kwargs):\n",
    "        for tbw in self.tb_writers.values():\n",
    "            tbw.close()\n",
    "        self.tb_writers = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea4730e-7937-48f4-8309-786ee54a42f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "early_stopping = EarlyStoppingCallback(early_stopping_patience= 6, \n",
    "                                    early_stopping_threshold= 0.055)\n",
    "train_dataset = load_from_disk(os.path.join(dataset_path, \"train\"))\n",
    "eval_dataset = load_from_disk(os.path.join(dataset_path, \"eval\"))\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    #compute_metrics=compute_metrics, #slow down training\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset, # eval is slower with compute_metrics\n",
    "    #callbacks= [CombinedTensorBoardCallback]\n",
    "    callbacks= [early_stopping,CombinedTensorBoardCallback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5ab7cb-2c44-4531-b54b-b018cfa517f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f73281b2-699b-4dab-b06a-233ca9e1be38",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.profiler\n",
    "import time\n",
    "\n",
    "class ProfCallback(TrainerCallback):\n",
    "    def __init__(self, prof):\n",
    "        self.prof = prof\n",
    "\n",
    "    def on_step_end(self, args, state, control, **kwargs):\n",
    "        self.prof.step()\n",
    "\n",
    "start_time = time.time()\n",
    "with torch.profiler.profile(activities=[torch.profiler.ProfilerActivity.CPU,\n",
    "                                        torch.profiler.ProfilerActivity.CUDA], \n",
    "                            schedule=torch.profiler.schedule(skip_first=3, wait=1, warmup=1, active=2, repeat=2),\n",
    "                            on_trace_ready=torch.profiler.tensorboard_trace_handler(training_output),\n",
    "                            profile_memory=True,\n",
    "                            with_stack=True,\n",
    "                            record_shapes=True) as prof:\n",
    "    trainer.add_callback(ProfCallback(prof=prof))\n",
    "    trainer.train()\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Training took {elapsed_time:.2f} seconds\")\n",
    "with open(\"training_time.txt\", \"w\") as file:\n",
    "    file.write(f\"Training took {elapsed_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8aca6e0-787e-47b7-9024-632bebeaa1f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainer.save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885eb1a5-400e-4a9a-8a08-9af85cf793b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer.save_pretrained(training_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6449cf4-8f65-4718-92c1-c07ea424ae31",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainer.create_model_card()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e223398e-68ff-4c55-a731-5fc6d28b272c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reset kernel if OOM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "397c397b-602f-4fe9-9a80-be035b17a9a4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cdsw/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "\n",
      "Parameters:\n",
      "Total parameters: 737.6681 M\n",
      "\n",
      "Data types:\n",
      "torch.float32, 737.6681 M, 100.00 %\n"
     ]
    }
   ],
   "source": [
    "ft_model = \"trainoutput-wikisql\"\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "import torch\n",
    "from torch import cuda\n",
    "\n",
    "device_map = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device_map)\n",
    "\n",
    "#model = AutoModelForSeq2SeqLM.from_pretrained(ft_model,device_map=device_map)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(ft_model,device_map=\"cpu\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(ft_model)\n",
    "from datasets import load_dataset\n",
    "\n",
    "test_data = load_dataset('wikisql', split='test')\n",
    "\n",
    "def translate_to_sql(text):\n",
    "    inputs = tokenizer(text, padding='longest', max_length=128, return_tensors='pt').to(\"cpu\")\n",
    "    #inputs = tokenizer(text, padding='longest', max_length=128, return_tensors='pt').to(device_map)\n",
    "    input_ids = inputs.input_ids\n",
    "    #attention_mask = inputs.attention_mask\n",
    "    #output = model.generate(input_ids, attention_mask=attention_mask, max_length=64)\n",
    "    output = model.generate(input_ids, max_length=96)\n",
    "    \n",
    "    return tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "def print_param_precision(model):\n",
    "  dtypes = {}\n",
    "  for _, p in model.named_parameters():\n",
    "      dtype = p.dtype\n",
    "      if dtype not in dtypes:\n",
    "          dtypes[dtype] = 0\n",
    "      dtypes[dtype] += p.numel()\n",
    "  total = 0\n",
    "  for k, v in dtypes.items():\n",
    "      total += v\n",
    "  for k, v in dtypes.items():\n",
    "      print(f\"{k}, {v / 10**6:.4f} M, {v / total*100:.2f} %\")\n",
    "\n",
    "def print_parameters(model):\n",
    "  # Count the total parameters\n",
    "  total_params = sum(p.numel() for p in model.parameters())\n",
    "  print(f\"Total parameters: {total_params/10**6:.4f} M\")\n",
    "\n",
    "print(\"\\nParameters:\")\n",
    "print_parameters(model)\n",
    "print(\"\\nData types:\")\n",
    "print_param_precision(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3421b25f-c0b7-428c-aff6-907746c45d05",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Instruction: How many different nationalities do the players of New Jersey Devils come from?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cdsw/.local/lib/python3.10/site-packages/transformers/generation/utils.py:1518: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use and modify the model generation configuration (see https://huggingface.co/docs/transformers/generation_strategies#default-text-generation-configuration )\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Prediction: COUNT Nationality FROM table WHERE NHL team = New Jersey Devils\n",
      "Expected Answer: SELECT COUNT Nationality FROM table WHERE NHL team = New Jersey Devils\n",
      "=================================\n",
      "\n",
      "Test Instruction: What is the nationality of the player from Vancouver Canucks?\n",
      "Model Prediction: SELECT Nationality FROM table WHERE NHL team = Vancouver Canucks\n",
      "Expected Answer: SELECT Nationality FROM table WHERE NHL team = Vancouver Canucks\n",
      "=================================\n",
      "\n",
      "Test Instruction: When were the ships launched that were laid down on september 1, 1964?\n",
      "Model Prediction: SELECT Launched FROM table WHERE Laid Down = september 1, 1964\n",
      "Expected Answer: SELECT Launched FROM table WHERE Laid down = September 1, 1964\n",
      "=================================\n",
      "\n",
      "Test Instruction: List the # for ships commissioned on september 30, 1967.\n",
      "Model Prediction: SELECT # FROM table WHERE Commissioned = september 30, 1967\n",
      "Expected Answer: SELECT # FROM table WHERE Commissioned = September 30, 1967\n",
      "=================================\n",
      "\n",
      "Test Instruction:  What could a spanish coronel be addressed as in the commonwealth military?\n",
      "Model Prediction: SELECT Commonwealth Military Addresses FROM table WHERE Name = Spanish Coronal\n",
      "Expected Answer: SELECT Commonwealth equivalent FROM table WHERE Rank in Spanish = Coronel\n",
      "=================================\n",
      "\n",
      "Inference took 10.66 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "for i in range(10,20,2):\n",
    "  print('Test Instruction: ' + test_data[i]['question'])\n",
    "  print('Model Prediction: ' + translate_to_sql('translate to SQL: ' + test_data[i]['question']))\n",
    "  print('Expected Answer: ' + test_data[i]['sql']['human_readable'])\n",
    "  print('=================================\\n')\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Inference took {elapsed_time:.2f} seconds\")\n",
    "with open(\"Inference_time.txt\", \"w\") as file:\n",
    "    file.write(f\"Inference took {elapsed_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bae8fc3-35c5-4f89-8775-8d2e7c59e3ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d37332-b939-4e4a-bb34-ad4152db6e16",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
