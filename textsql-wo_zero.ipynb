{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bbb8ca14-ef56-4452-97a6-95247be66427",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cdsw/.local/lib/python3.9/site-packages/datasets/table.py:1421: FutureWarning: promote has been superseded by mode='default'.\n",
      "  table = cls._concat_blocks(blocks, axis=0)\n"
     ]
    }
   ],
   "source": [
    "base_model = 'google/flan-t5-large'\n",
    "dataset_path = \"wikisql_tok_dataset\"\n",
    "\n",
    "from datasets import load_dataset\n",
    "import shutil\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer, T5ForConditionalGeneration\n",
    "from datasets import load_from_disk\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model)\n",
    "model = T5ForConditionalGeneration.from_pretrained(base_model)\n",
    "\n",
    "#CKPT = 'facebook/bart-large'\n",
    "#from transformers import AutoTokenizer, BartTokenizer, BartModel, BartForConditionalGeneration\n",
    "#tokenizer = AutoTokenizer.from_pretrained('facebook/bart-large')\n",
    "#model = BartForConditionalGeneration.from_pretrained('facebook/bart-large')\n",
    "\n",
    "train_data = load_dataset('wikisql', split=\"train[:100%]+validation[:100%]\")\n",
    "#train_data = load_dataset('wikisql', split=\"train+validation\")\n",
    "test_data = load_dataset('wikisql', split='test')\n",
    "\n",
    "def format_dataset(example):\n",
    " return {'input': 'translate to SQL: ' + example['question'], 'target': example['sql']['human_readable']}\n",
    "\n",
    "train_data = train_data.map(format_dataset, remove_columns=train_data.column_names)\n",
    "test_data = test_data.map(format_dataset, remove_columns=test_data.column_names)\n",
    "\n",
    "def remove_dir(dir_path):\n",
    "    try:\n",
    "        shutil.rmtree(dir_path)\n",
    "        print(f\"Folder '{dir_path}' has been deleted.\")\n",
    "    except Exception as e:\n",
    "        # Ignore errors, you can print a message if needed\n",
    "        print(f\"Folder '{dir_path}' has been deleted.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53249be2-35a6-4c42-90f5-6e164cbb2dd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0 Memory Used: 2987.4805 MB\n",
      "\n",
      "Parameters:\n",
      "Total parameters: 783.1501 M\n",
      "\n",
      "Data types:\n",
      "torch.float32, 783.1501 M, 100.00 %\n"
     ]
    }
   ],
   "source": [
    "def print_param_precision(model):\n",
    "  dtypes = {}\n",
    "  for _, p in model.named_parameters():\n",
    "      dtype = p.dtype\n",
    "      if dtype not in dtypes:\n",
    "          dtypes[dtype] = 0\n",
    "      dtypes[dtype] += p.numel()\n",
    "  total = 0\n",
    "  for k, v in dtypes.items():\n",
    "      total += v\n",
    "  for k, v in dtypes.items():\n",
    "      print(f\"{k}, {v / 10**6:.4f} M, {v / total*100:.2f} %\")\n",
    "\n",
    "def print_parameters(model):\n",
    "  # Count the total parameters\n",
    "  total_params = sum(p.numel() for p in model.parameters())\n",
    "  print(f\"Total parameters: {total_params/10**6:.4f} M\")\n",
    "\n",
    "device_map = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"{device_map} Memory Used: {model.get_memory_footprint() / 1024**2:.4f} MB\")\n",
    "print(\"\\nParameters:\")\n",
    "print_parameters(model)\n",
    "print(\"\\nData types:\")\n",
    "print_param_precision(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c9631a1-5416-4c82-91c8-ebc2f3ded8f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input', 'target'],\n",
       "    num_rows: 64776\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20095e22-344f-478f-8620-b5e81c8f14d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2640d15e34f448088b76855886d62b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Mean: 19.8971, %-Input > 256:0.0,  %-Input > 128:0.0, %-Input > 64:0.0002 Output Mean:20.0403, %-Output > 256:0.0, %-Output > 128:0.0002, %-Output > 64:0.0005\n"
     ]
    }
   ],
   "source": [
    "def map_to_length(x):\n",
    "  x[\"input_len\"] = len(tokenizer(x[\"input\"]).input_ids)\n",
    "  x[\"input_longer_256\"] = int(x[\"input_len\"] > 256)\n",
    "  x[\"input_longer_128\"] = int(x[\"input_len\"] > 128)\n",
    "  x[\"input_longer_64\"] = int(x[\"input_len\"] > 64)\n",
    "  x[\"out_len\"] = len(tokenizer(x[\"target\"]).input_ids)\n",
    "  x[\"out_longer_256\"] = int(x[\"out_len\"] > 256)\n",
    "  x[\"out_longer_128\"] = int(x[\"out_len\"] > 128)\n",
    "  x[\"out_longer_64\"] = int(x[\"out_len\"] > 64)\n",
    "  return x\n",
    "\n",
    "sample_size = 10000\n",
    "data_stats = train_data.select(range(sample_size)).map(map_to_length, num_proc=4)\n",
    "\n",
    "def compute_and_print_stats(x):\n",
    "  if len(x[\"input_len\"]) == sample_size:\n",
    "    print(\n",
    "        \"Input Mean: {}, %-Input > 256:{},  %-Input > 128:{}, %-Input > 64:{} Output Mean:{}, %-Output > 256:{}, %-Output > 128:{}, %-Output > 64:{}\".format(\n",
    "            sum(x[\"input_len\"]) / sample_size,\n",
    "            sum(x[\"input_longer_256\"]) / sample_size,\n",
    "            sum(x[\"input_longer_128\"]) / sample_size,\n",
    "            sum(x[\"input_longer_64\"]) / sample_size,   \n",
    "            sum(x[\"out_len\"]) / sample_size,\n",
    "            sum(x[\"out_longer_256\"]) / sample_size,\n",
    "            sum(x[\"out_longer_128\"]) / sample_size,\n",
    "            sum(x[\"out_longer_64\"]) / sample_size,\n",
    "        )\n",
    "    )\n",
    "\n",
    "output = data_stats.map(\n",
    "  compute_and_print_stats, \n",
    "  batched=True,\n",
    "  batch_size=-1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d2fcd398-7655-4d4e-9bc0-d9386ba3e7f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_features(example_batch):\n",
    "    input_encodings = tokenizer.batch_encode_plus(example_batch['input'], truncation = True, padding=\"max_length\", max_length=128)\n",
    "    target_encodings = tokenizer.batch_encode_plus(example_batch['target'], truncation = True, padding=\"max_length\", max_length=128)\n",
    "   \n",
    "    encodings = {\n",
    "        'input_ids': input_encodings['input_ids'],\n",
    "        'labels': target_encodings['input_ids']\n",
    "    }\n",
    "\n",
    "    return encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "712cc95b-8780-4db3-b2a5-d3d009395b29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b07c2d6e62624fe8940e23e0229c8b80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/64776 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecf5bf110d8f485aa16fc3e13825773c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/15878 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_data = train_data.map(convert_to_features, batched=True, remove_columns=train_data.column_names)\n",
    "test_data = test_data.map(convert_to_features, batched=True, remove_columns=test_data.column_names)\n",
    "\n",
    "#columns = ['input_ids', 'attention_mask', 'labels', 'decoder_attention_mask']\n",
    "columns = ['input_ids', 'labels']\n",
    "\n",
    "train_data.set_format(type='torch', columns=columns)\n",
    "test_data.set_format(type='torch', columns=columns)\n",
    "\n",
    "train_data.save_to_disk(os.path.join(dataset_path,\"train\"))\n",
    "test_data.save_to_disk(os.path.join(dataset_path,\"eval\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "73057e5d-97ff-457f-89ba-ada4b55036c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Seq2SeqTrainer, Seq2SeqTrainingArguments, DataCollatorForSeq2Seq\n",
    "from transformers import TrainerCallback, EarlyStoppingCallback, is_tensorboard_available\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ee3a0f7-403d-458a-bfc1-3fb31b1bdcaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder 'trainoutput-wikisql' has been deleted.\n"
     ]
    }
   ],
   "source": [
    "training_output = \"trainoutput-wikisql\"\n",
    "remove_dir(training_output)\n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=training_output,\n",
    "    per_device_train_batch_size=32,\n",
    "    num_train_epochs=5, # Below 5 will result in failed inference.\n",
    "    per_device_eval_batch_size=32,\n",
    "    predict_with_generate=True,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    do_train=True,\n",
    "    do_eval=True,\n",
    "    logging_steps=500,\n",
    "    save_strategy=\"epoch\",\n",
    "    report_to=\"tensorboard\", #bypass MLflow\n",
    "    load_best_model_at_end=True,\n",
    "    overwrite_output_dir=True,\n",
    "    fp16=True, #lower VRAM utilization\n",
    "    #bf16=True, #not working for every GPU\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e4aec6ea-386b-424f-954d-d3f7e5ebc9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_preds):\n",
    "    preds, labels = eval_preds\n",
    "\n",
    "    # decode preds and labels\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    # rougeLSum expects newline after each sentence\n",
    "    decoded_preds = [\"\\n\".join(nltk.sent_tokenize(pred.strip())) for pred in decoded_preds]\n",
    "    decoded_labels = [\"\\n\".join(nltk.sent_tokenize(label.strip())) for label in decoded_labels]\n",
    "\n",
    "    result = metric.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3c0da20a-ebde-4844-a480-1907bb896f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_rewrite_logs(d, mode):\n",
    "    new_d = {}\n",
    "    eval_prefix = \"eval_\"\n",
    "    eval_prefix_len = len(eval_prefix)\n",
    "    test_prefix = \"test_\"\n",
    "    test_prefix_len = len(test_prefix)\n",
    "    for k, v in d.items():\n",
    "        if mode == 'eval' and k.startswith(eval_prefix):\n",
    "            if k[eval_prefix_len:] == 'loss':\n",
    "                new_d[\"combined/\" + k[eval_prefix_len:]] = v\n",
    "        elif mode == 'test' and k.startswith(test_prefix):\n",
    "            if k[test_prefix_len:] == 'loss':\n",
    "                new_d[\"combined/\" + k[test_prefix_len:]] = v\n",
    "        elif mode == 'train':\n",
    "            if k == 'loss':\n",
    "                new_d[\"combined/\" + k] = v\n",
    "    return new_d\n",
    "\n",
    "\n",
    "class CombinedTensorBoardCallback(TrainerCallback):\n",
    "    \"\"\"\n",
    "    A [`TrainerCallback`] that sends the logs to [TensorBoard](https://www.tensorflow.org/tensorboard).\n",
    "    Args:\n",
    "        tb_writer (`SummaryWriter`, *optional*):\n",
    "            The writer to use. Will instantiate one if not set.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, tb_writers=None):\n",
    "        has_tensorboard = is_tensorboard_available()\n",
    "        if not has_tensorboard:\n",
    "            raise RuntimeError(\n",
    "                \"TensorBoardCallback requires tensorboard to be installed. Either update your PyTorch version or\"\n",
    "                \" install tensorboardX.\"\n",
    "            )\n",
    "        if has_tensorboard:\n",
    "            try:\n",
    "                from torch.utils.tensorboard import SummaryWriter  # noqa: F401\n",
    "\n",
    "                self._SummaryWriter = SummaryWriter\n",
    "            except ImportError:\n",
    "                try:\n",
    "                    from tensorboardX import SummaryWriter\n",
    "\n",
    "                    self._SummaryWriter = SummaryWriter\n",
    "                except ImportError:\n",
    "                    self._SummaryWriter = None\n",
    "        else:\n",
    "            self._SummaryWriter = None\n",
    "        self.tb_writers = tb_writers\n",
    "\n",
    "    def _init_summary_writer(self, args, log_dir=None):\n",
    "        log_dir = log_dir or args.logging_dir\n",
    "        if self._SummaryWriter is not None:\n",
    "            self.tb_writers = dict(train=self._SummaryWriter(log_dir=os.path.join(log_dir, 'train')),\n",
    "                                   eval=self._SummaryWriter(log_dir=os.path.join(log_dir, 'eval')))\n",
    "\n",
    "    def on_train_begin(self, args, state, control, **kwargs):\n",
    "        if not state.is_world_process_zero:\n",
    "            return\n",
    "\n",
    "        log_dir = None\n",
    "\n",
    "        if state.is_hyper_param_search:\n",
    "            trial_name = state.trial_name\n",
    "            if trial_name is not None:\n",
    "                log_dir = os.path.join(args.logging_dir, trial_name)\n",
    "\n",
    "        if self.tb_writers is None:\n",
    "            self._init_summary_writer(args, log_dir)\n",
    "\n",
    "        for k, tbw in self.tb_writers.items():\n",
    "            tbw.add_text(\"args\", args.to_json_string())\n",
    "            if \"model\" in kwargs:\n",
    "                model = kwargs[\"model\"]\n",
    "                if hasattr(model, \"config\") and model.config is not None:\n",
    "                    model_config_json = model.config.to_json_string()\n",
    "                    tbw.add_text(\"model_config\", model_config_json)\n",
    "            # Version of TensorBoard coming from tensorboardX does not have this method.\n",
    "            if hasattr(tbw, \"add_hparams\"):\n",
    "                tbw.add_hparams(args.to_sanitized_dict(), metric_dict={})\n",
    "\n",
    "    def on_log(self, args, state, control, logs=None, **kwargs):\n",
    "        if not state.is_world_process_zero:\n",
    "            return\n",
    "\n",
    "        if self.tb_writers is None:\n",
    "            self._init_summary_writer(args)\n",
    "\n",
    "        for tbk, tbw in self.tb_writers.items():\n",
    "            logs_new = custom_rewrite_logs(logs, mode=tbk)\n",
    "            for k, v in logs_new.items():\n",
    "                if isinstance(v, (int, float)):\n",
    "                    tbw.add_scalar(k, v, state.global_step)\n",
    "                else:\n",
    "                    logger.warning(\n",
    "                        \"Trainer is attempting to log a value of \"\n",
    "                        f'\"{v}\" of type {type(v)} for key \"{k}\" as a scalar. '\n",
    "                        \"This invocation of Tensorboard's writer.add_scalar() \"\n",
    "                        \"is incorrect so we dropped this attribute.\"\n",
    "                    )\n",
    "            tbw.flush()\n",
    "\n",
    "    def on_train_end(self, args, state, control, **kwargs):\n",
    "        for tbw in self.tb_writers.values():\n",
    "            tbw.close()\n",
    "        self.tb_writers = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0ea4730e-7937-48f4-8309-786ee54a42f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    }
   ],
   "source": [
    "early_stopping = EarlyStoppingCallback(early_stopping_patience= 5, \n",
    "                                    early_stopping_threshold= 0.001)\n",
    "train_dataset = load_from_disk(os.path.join(dataset_path, \"train\"))\n",
    "eval_dataset = load_from_disk(os.path.join(dataset_path, \"eval\"))\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    compute_metrics=compute_metrics,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    callbacks= [early_stopping,CombinedTensorBoardCallback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8c5ab7cb-2c44-4531-b54b-b018cfa517f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f73281b2-699b-4dab-b06a-233ca9e1be38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='693' max='10125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  693/10125 05:25 < 1:14:02, 2.12 it/s, Epoch 0.34/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W kineto_shim.cpp:372] Profiler is not initialized: skipping step() invocation\n",
      "[W kineto_shim.cpp:372] Profiler is not initialized: skipping step() invocation\n",
      "[W kineto_shim.cpp:372] Profiler is not initialized: skipping step() invocation\n",
      "STAGE:2023-11-30 00:52:12 2184:2184 ActivityProfilerController.cpp:312] Completed Stage: Warm Up\n",
      "STAGE:2023-11-30 00:52:14 2184:2184 ActivityProfilerController.cpp:318] Completed Stage: Collection\n",
      "STAGE:2023-11-30 00:52:14 2184:2184 ActivityProfilerController.cpp:322] Completed Stage: Post Processing\n",
      "STAGE:2023-11-30 00:52:31 2184:2184 ActivityProfilerController.cpp:312] Completed Stage: Warm Up\n",
      "STAGE:2023-11-30 00:52:33 2184:2184 ActivityProfilerController.cpp:318] Completed Stage: Collection\n",
      "STAGE:2023-11-30 00:52:33 2184:2184 ActivityProfilerController.cpp:322] Completed Stage: Post Processing\n"
     ]
    }
   ],
   "source": [
    "import torch.profiler\n",
    "\n",
    "class ProfCallback(TrainerCallback):\n",
    "    def __init__(self, prof):\n",
    "        self.prof = prof\n",
    "\n",
    "    def on_step_end(self, args, state, control, **kwargs):\n",
    "        self.prof.step()\n",
    "        \n",
    "with torch.profiler.profile(activities=[torch.profiler.ProfilerActivity.CPU,\n",
    "                                        torch.profiler.ProfilerActivity.CUDA], \n",
    "                            schedule=torch.profiler.schedule(skip_first=3, wait=1, warmup=1, active=2, repeat=2),\n",
    "                            on_trace_ready=torch.profiler.tensorboard_trace_handler(training_output),\n",
    "                            profile_memory=True,\n",
    "                            with_stack=True,\n",
    "                            record_shapes=True) as prof:\n",
    "    trainer.add_callback(ProfCallback(prof=prof))\n",
    "    trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8aca6e0-787e-47b7-9024-632bebeaa1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885eb1a5-400e-4a9a-8a08-9af85cf793b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.save_pretrained(training_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6449cf4-8f65-4718-92c1-c07ea424ae31",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.create_model_card()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e223398e-68ff-4c55-a731-5fc6d28b272c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clear kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "397c397b-602f-4fe9-9a80-be035b17a9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ft_model = \"trainoutput-wikisql\"\n",
    "ft_model = training_output\n",
    "#base_model = 't5-small'\n",
    "#ft_model = base_model\n",
    "from transformers import AutoTokenizer, T5ForConditionalGeneration\n",
    "tokenizer = AutoTokenizer.from_pretrained(ft_model)\n",
    "model = T5ForConditionalGeneration.from_pretrained(ft_model)\n",
    "from datasets import load_dataset\n",
    "\n",
    "test_data = load_dataset('wikisql', split='test')\n",
    "\n",
    "def translate_to_sql(text):\n",
    "    inputs = tokenizer(text, padding='longest', max_length=128, return_tensors='pt')\n",
    "    input_ids = inputs.input_ids\n",
    "    attention_mask = inputs.attention_mask\n",
    "    #output = model.generate(input_ids, attention_mask=attention_mask, max_length=64)\n",
    "    output = model.generate(input_ids, max_length=128)\n",
    "    \n",
    "    return tokenizer.decode(output[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa330f81-aa6c-41ad-af79-c34f07b2ba60",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(200,300,20):\n",
    "  print('translate to SQL: ' + test_data[i]['question'])\n",
    "  print('Predict. :' + translate_to_sql('translate to SQL: ' + test_data[i]['question']))\n",
    "  print('Expected: ' + test_data[i]['sql']['human_readable'])\n",
    "  print('=================================\\n')\n",
    "    \n",
    "\n",
    "text = \"translate to SQL: How many model with BERT architecture are in the HuggingFace Hub?\"\n",
    "#text = \"translate to SQL: The stenhousemuir team had how many highest attendances?\"\n",
    "translate_to_sql(text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
