{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c4f9c1-5a88-4c4f-b7cc-e17a5dd7a834",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "def print_param_precision(model):\n",
    "  dtypes = {}\n",
    "  for _, p in model.named_parameters():\n",
    "      dtype = p.dtype\n",
    "      if dtype not in dtypes:\n",
    "          dtypes[dtype] = 0\n",
    "      dtypes[dtype] += p.numel()\n",
    "  total = 0\n",
    "  for k, v in dtypes.items():\n",
    "      total += v\n",
    "  for k, v in dtypes.items():\n",
    "      print(f\"{k}, {v / 10**6:.4f} M, {v / total*100:.2f} %\")\n",
    "\n",
    "def print_parameters(model):\n",
    "  # Count the total parameters\n",
    "  total_params = sum(p.numel() for p in model.parameters())\n",
    "  print(f\"Total parameters: {total_params/10**6:.4f} M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d841315-9c09-4dd1-8ec2-cf722b38fd9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_model = \"merged_bloom-1b1\"\n",
    "device_map = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "#ft_model = AutoModelForCausalLM.from_pretrained(merged_model, torch_dtype=torch.float16, device_map=device_map)\n",
    "ft_model = AutoModelForCausalLM.from_pretrained(merged_model, device_map=device_map)\n",
    "ft_tokenizer = AutoTokenizer.from_pretrained(merged_model,device_map=device_map)\n",
    "print(f\"{device_map} Memory Used: {ft_model.get_memory_footprint() / 1024**2:.4f} MB\")\n",
    "print(\"\\nParameters:\")\n",
    "print_parameters(ft_model)\n",
    "print(\"\\nData types:\")\n",
    "print_param_precision(ft_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15895a2e-e0e5-41ae-bbfe-31390778fab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mytask=\"CREATE TABLE trip (bus_stop VARCHAR, duration INTEGER), list all the bus stops from which a trip of duration below 100 started.\"\n",
    "mytask=\"CREATE TABLE book (Title VARCHAR, Writer VARCHAR). What are the titles of the books whose writer is not Dennis Lee?\"\n",
    "prompt = f\"\"\"\n",
    "# Instruction:\n",
    "Use the context below to produce the result\n",
    "# context:\n",
    "{mytask}\n",
    "# result:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd88fa0d-d84c-43d2-8bb7-4e45398ee463",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_id1 = ft_tokenizer.encode(prompt, return_tensors=\"pt\").to(device_map)\n",
    "attention_mask1 = torch.ones(input_id1.shape, dtype=torch.long).to(device_map)\n",
    "print(f\"--------------------------------------\")\n",
    "print(f\"Prompt:\\n{prompt}\")\n",
    "print(f\"--------------------------------------\")\n",
    "\n",
    "print(f\"Fine-tuned Model Result :\\n\")\n",
    "output_ft = ft_model.generate(input_ids=input_id1, do_sample=True, max_new_tokens=100, top_p=0.9,temperature=0.5,attention_mask=attention_mask1)\n",
    "print(f\"{ft_tokenizer.batch_decode(output_ft.detach().cpu().numpy(), skip_special_tokens=True)[0][len(prompt):]}\")\n",
    "print(f\"--------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61531e63-b352-4669-93d3-ea0969ac8f3c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
